# ModularQA
ModularQA is a QA system that answers complex multi-hop and discrete reasoning questions by decomposing them into sub-questions answerable by two sub-models: a neural factoid single-span QA model and a symbolic calculator. These sub-questions and answers provided by the sub-model provide a natural language explanation of the
modelâ€™s reasoning. This system is designed and trained based on the Text Modular Networks framework where the decompositions are generated in the language of the sub-models without needing annotated decompositions. For more details, refer to the [paper](https://www.semanticscholar.org/paper/0e1d82d24d58433ce9e211551605a0bfd296624f).



## Paper
```
Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models
Tushar Khot, Daniel Khashabi, Kyle Richardson, Peter Clark, Ashish Sabharwal
NAACL 2021
```
Bibtex:
```
@inproceedings{WhatsMissing19,
  title={Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models},
  author={Tushar Khot, Daniel Khashabi, Kyle Richardson, Peter Clark, Ashish Sabharwal},
  booktitle={NAACL},
  year={2021}
}
```


## Demo
[https://modularqa-demo.apps.allenai.org/](https://modularqa-demo.apps.allenai.org/)

Note that responses might be slow

## Data
We used the following subsets of HotpotQA and DROP to train and evaluate our models
 * [HotpotQA](https://ai2-public-datasets.s3.amazonaws.com/modularqa/hotpot_subset.zip)
 * [DROP](https://ai2-public-datasets.s3.amazonaws.com/modularqa/drop_subset.zip)
 * [DROP Evaluation Partitions](https://ai2-public-datasets.s3.amazonaws.com/modularqa/drop_partitions.zip)


[NextGen Training Data](https://ai2-public-datasets.s3.amazonaws.com/modularqa/modularqa_nextgen_train.zip):
The decomposition chains generated from these DROP+HotpotQA subsets. These chains were used to train the NextGen model.

[Chains Scorer Training Data](https://ai2-public-datasets.s3.amazonaws.com/modularqa/chains_scorer_training.zip):
The chains generated by running inference using our NextGen model with associated labels: 1 indicates the final answer produced by this chain is correct (F1>0.2) and 0 indicates incorrect.

## Models
We also provide the trained models used in our system.

[NextGen Model](https://ai2-public-datasets.s3.amazonaws.com/modularqa/nextgen_model.zip):
A BART-Large model trained to produce the next sub-question given the complex question and previous question-answer pairs. Sample input-output:
```
  Input:
    QC: When did the magazine Wallace Hester work for run? QI: (squad) What magazine did Hester work for? A: "Vanity Fair". QS:

  Output:
    (squad) When did the second Vanity Fair run?
```

[Chains Scorer Model](https://ai2-public-datasets.s3.amazonaws.com/modularqa/chains_scorer.zip):
A RoBERTa-Large model trained to predict whether the final answer produced by an inference chain is correct (captured by the score for the label 1). Sample input:
```
   QC: How many percent of jobs were not in wholesale? QI: (squad)What percent of jobs are in wholesale? A: 12.4 QI: (math)not(12.4) A: 87.6 QS: [EOQ]
```




## Code
We use a fork of the [HuggingFace Transformers](https://github.com/huggingface/transformers) codebase: [https://github.com/tusharkhot/transformers/tree/modularqav2](https://github.com/tusharkhot/transformers/tree/modularqav2). This is based on an older version of the Transformers codebase.





